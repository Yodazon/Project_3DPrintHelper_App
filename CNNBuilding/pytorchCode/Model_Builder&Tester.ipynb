{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to build a model for recongition of 3D printing mishaps and good prints\n",
    "\n",
    "The following code has the following setup, it has a combiantion fo photos from \"printing_errors_original\" and \"print_errors_2_modified_for_test\"made into a folder called \"images_combined\n",
    "\n",
    "A training,validation and test set from \"images_combined\". This folder is organzied by class\n",
    "\n",
    "The goal for this model is to train on a mix of lab setting and real world photos to see if the model can perform better than the model in \"model_testing_seperated\" jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  784\n"
     ]
    }
   ],
   "source": [
    "#Import libraries that will be needed\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import ToTensor\n",
    "import random \n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 784\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'good', 1: 'spaghetti', 2: 'stringing', 3: 'underextrusion'}\n"
     ]
    }
   ],
   "source": [
    "#import folders for train and test\n",
    "image_directory = \"..\\\\images_combined\"\n",
    "\n",
    "\n",
    "class_names = sorted(os.listdir(image_directory))\n",
    "class_mapping = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.000001\n",
    "batch = 25\n",
    "image_size = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your image directory path\n",
    "image_directory = \"..\\\\images_combined\"\n",
    "\n",
    "# Create a custom dataset\n",
    "custom_dataset = datasets.ImageFolder(root=image_directory,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize(image_size),\n",
    "                                          transforms.CenterCrop(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modified Code, got rid of test set March 10, 2024\n",
    "###\n",
    "\n",
    "# Calculate the train, validation, and test sizes\n",
    "train_size = int(0.7 * len(custom_dataset))  # 70% for training\n",
    "val_size = int(0.1 * len(custom_dataset)) # 10% for validation\n",
    "test_size = len(custom_dataset) - train_size - val_size  # Remaining 20% for testing\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    custom_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# PyTorch Data Initialization\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch, shuffle=False, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch, shuffle=False, num_workers=2)\n",
    "\n",
    "# Using ngpu\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "\n",
    "#PyTorch\n",
    "#Second PyTorch Model\n",
    "#AlexNet Architecture\n",
    "\n",
    "class pyTorchModel_2(nn.Module):\n",
    "    def __init__(self,ngpu, num_classes=4):\n",
    "        super(pyTorchModel_2, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "pymodel1 = pyTorchModel_2(ngpu).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If only one model\n",
    "optimizer1 = torch.optim.RMSprop(pymodel1.parameters(), lr=lr )\n",
    "\n",
    "torch.use_deterministic_algorithms(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, trainLoss):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        #TrainLoss.append(loss.item())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    trainLoss.append(train_loss)\n",
    "    \n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, testLoss, acc):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #testLoss.append(test_loss.item())\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    testLoss.append(test_loss)\n",
    "    acc.append((100*correct))\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "def validate(model, dataloader, loss_fn, valLoss, acc):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    valLoss.append(val_loss)\n",
    "    acc.append((100 * correct))\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.283471  [   25/11687]\n",
      "loss: 0.921096  [ 2525/11687]\n",
      "loss: 0.871764  [ 5025/11687]\n",
      "loss: 1.169045  [ 7525/11687]\n",
      "loss: 1.218938  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.837549 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.896046  [   25/11687]\n",
      "loss: 0.832135  [ 2525/11687]\n",
      "loss: 0.850923  [ 5025/11687]\n",
      "loss: 0.819049  [ 7525/11687]\n",
      "loss: 0.546845  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.725164 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.725020  [   25/11687]\n",
      "loss: 0.818130  [ 2525/11687]\n",
      "loss: 0.640722  [ 5025/11687]\n",
      "loss: 0.590619  [ 7525/11687]\n",
      "loss: 0.760907  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.591223 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.709688  [   25/11687]\n",
      "loss: 0.747252  [ 2525/11687]\n",
      "loss: 0.793040  [ 5025/11687]\n",
      "loss: 0.606168  [ 7525/11687]\n",
      "loss: 0.634931  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.475360 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.672381  [   25/11687]\n",
      "loss: 0.502020  [ 2525/11687]\n",
      "loss: 0.574380  [ 5025/11687]\n",
      "loss: 0.572952  [ 7525/11687]\n",
      "loss: 0.576049  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.387611 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.238451  [   25/11687]\n",
      "loss: 0.472997  [ 2525/11687]\n",
      "loss: 0.391565  [ 5025/11687]\n",
      "loss: 0.435602  [ 7525/11687]\n",
      "loss: 0.476557  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.322369 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.433532  [   25/11687]\n",
      "loss: 0.235730  [ 2525/11687]\n",
      "loss: 0.432160  [ 5025/11687]\n",
      "loss: 0.212973  [ 7525/11687]\n",
      "loss: 0.411683  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.258754 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.438520  [   25/11687]\n",
      "loss: 0.209597  [ 2525/11687]\n",
      "loss: 0.294485  [ 5025/11687]\n",
      "loss: 0.427276  [ 7525/11687]\n",
      "loss: 0.290917  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.210318 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.191634  [   25/11687]\n",
      "loss: 0.351228  [ 2525/11687]\n",
      "loss: 0.088902  [ 5025/11687]\n",
      "loss: 0.137143  [ 7525/11687]\n",
      "loss: 0.404788  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.181678 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.097361  [   25/11687]\n",
      "loss: 0.432471  [ 2525/11687]\n",
      "loss: 0.477157  [ 5025/11687]\n",
      "loss: 0.220559  [ 7525/11687]\n",
      "loss: 0.184929  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.167241 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.300469  [   25/11687]\n",
      "loss: 0.127974  [ 2525/11687]\n",
      "loss: 0.128417  [ 5025/11687]\n",
      "loss: 0.154709  [ 7525/11687]\n",
      "loss: 0.085293  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.148305 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.125109  [   25/11687]\n",
      "loss: 0.142148  [ 2525/11687]\n",
      "loss: 0.177809  [ 5025/11687]\n",
      "loss: 0.138412  [ 7525/11687]\n",
      "loss: 0.146315  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.142440 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.219316  [   25/11687]\n",
      "loss: 0.105783  [ 2525/11687]\n",
      "loss: 0.114383  [ 5025/11687]\n",
      "loss: 0.284549  [ 7525/11687]\n",
      "loss: 0.137311  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.123803 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.068034  [   25/11687]\n",
      "loss: 0.053307  [ 2525/11687]\n",
      "loss: 0.049063  [ 5025/11687]\n",
      "loss: 0.116994  [ 7525/11687]\n",
      "loss: 0.218708  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.112992 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.163806  [   25/11687]\n",
      "loss: 0.401079  [ 2525/11687]\n",
      "loss: 0.126642  [ 5025/11687]\n",
      "loss: 0.025239  [ 7525/11687]\n",
      "loss: 0.216126  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.120258 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.035520  [   25/11687]\n",
      "loss: 0.041419  [ 2525/11687]\n",
      "loss: 0.133124  [ 5025/11687]\n",
      "loss: 0.176793  [ 7525/11687]\n",
      "loss: 0.172194  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.099302 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.045055  [   25/11687]\n",
      "loss: 0.038102  [ 2525/11687]\n",
      "loss: 0.083999  [ 5025/11687]\n",
      "loss: 0.029178  [ 7525/11687]\n",
      "loss: 0.176436  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.096439 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.184955  [   25/11687]\n",
      "loss: 0.099849  [ 2525/11687]\n",
      "loss: 0.321352  [ 5025/11687]\n",
      "loss: 0.112312  [ 7525/11687]\n",
      "loss: 0.135503  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.096235 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.107385  [   25/11687]\n",
      "loss: 0.063979  [ 2525/11687]\n",
      "loss: 0.136075  [ 5025/11687]\n",
      "loss: 0.026605  [ 7525/11687]\n",
      "loss: 0.095805  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.088384 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.048111  [   25/11687]\n",
      "loss: 0.162446  [ 2525/11687]\n",
      "loss: 0.046434  [ 5025/11687]\n",
      "loss: 0.061497  [ 7525/11687]\n",
      "loss: 0.012563  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.091807 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.046119  [   25/11687]\n",
      "loss: 0.029396  [ 2525/11687]\n",
      "loss: 0.011114  [ 5025/11687]\n",
      "loss: 0.062310  [ 7525/11687]\n",
      "loss: 0.139454  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.088343 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.091146  [   25/11687]\n",
      "loss: 0.045266  [ 2525/11687]\n",
      "loss: 0.064014  [ 5025/11687]\n",
      "loss: 0.237051  [ 7525/11687]\n",
      "loss: 0.018376  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.089490 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.168993  [   25/11687]\n",
      "loss: 0.026637  [ 2525/11687]\n",
      "loss: 0.067407  [ 5025/11687]\n",
      "loss: 0.081637  [ 7525/11687]\n",
      "loss: 0.235733  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.081437 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.047611  [   25/11687]\n",
      "loss: 0.017514  [ 2525/11687]\n",
      "loss: 0.043008  [ 5025/11687]\n",
      "loss: 0.169459  [ 7525/11687]\n",
      "loss: 0.071208  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.084843 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.045743  [   25/11687]\n",
      "loss: 0.007426  [ 2525/11687]\n",
      "loss: 0.046202  [ 5025/11687]\n",
      "loss: 0.049079  [ 7525/11687]\n",
      "loss: 0.084096  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.076962 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.017376  [   25/11687]\n",
      "loss: 0.036349  [ 2525/11687]\n",
      "loss: 0.051399  [ 5025/11687]\n",
      "loss: 0.025378  [ 7525/11687]\n",
      "loss: 0.015888  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.086599 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.036472  [   25/11687]\n",
      "loss: 0.009926  [ 2525/11687]\n",
      "loss: 0.129528  [ 5025/11687]\n",
      "loss: 0.019693  [ 7525/11687]\n",
      "loss: 0.139120  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.082227 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.010944  [   25/11687]\n",
      "loss: 0.009745  [ 2525/11687]\n",
      "loss: 0.122687  [ 5025/11687]\n",
      "loss: 0.025505  [ 7525/11687]\n",
      "loss: 0.011722  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.078187 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.010696  [   25/11687]\n",
      "loss: 0.023725  [ 2525/11687]\n",
      "loss: 0.006075  [ 5025/11687]\n",
      "loss: 0.053565  [ 7525/11687]\n",
      "loss: 0.045765  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.079849 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.026200  [   25/11687]\n",
      "loss: 0.190072  [ 2525/11687]\n",
      "loss: 0.001192  [ 5025/11687]\n",
      "loss: 0.023645  [ 7525/11687]\n",
      "loss: 0.004095  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.081528 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.051138  [   25/11687]\n",
      "loss: 0.071046  [ 2525/11687]\n",
      "loss: 0.044567  [ 5025/11687]\n",
      "loss: 0.106404  [ 7525/11687]\n",
      "loss: 0.075718  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.075886 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.006933  [   25/11687]\n",
      "loss: 0.016478  [ 2525/11687]\n",
      "loss: 0.032327  [ 5025/11687]\n",
      "loss: 0.004448  [ 7525/11687]\n",
      "loss: 0.001294  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.077104 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.042842  [   25/11687]\n",
      "loss: 0.016163  [ 2525/11687]\n",
      "loss: 0.004392  [ 5025/11687]\n",
      "loss: 0.002939  [ 7525/11687]\n",
      "loss: 0.006296  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.072965 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.057037  [   25/11687]\n",
      "loss: 0.028176  [ 2525/11687]\n",
      "loss: 0.006650  [ 5025/11687]\n",
      "loss: 0.001499  [ 7525/11687]\n",
      "loss: 0.015582  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.084747 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.012182  [   25/11687]\n",
      "loss: 0.017643  [ 2525/11687]\n",
      "loss: 0.014584  [ 5025/11687]\n",
      "loss: 0.003056  [ 7525/11687]\n",
      "loss: 0.036205  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.076333 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.015709  [   25/11687]\n",
      "loss: 0.005994  [ 2525/11687]\n",
      "loss: 0.034395  [ 5025/11687]\n",
      "loss: 0.005792  [ 7525/11687]\n",
      "loss: 0.009968  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.072863 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.002300  [   25/11687]\n",
      "loss: 0.065575  [ 2525/11687]\n",
      "loss: 0.004656  [ 5025/11687]\n",
      "loss: 0.019810  [ 7525/11687]\n",
      "loss: 0.001201  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.078217 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.006664  [   25/11687]\n",
      "loss: 0.001675  [ 2525/11687]\n",
      "loss: 0.072264  [ 5025/11687]\n",
      "loss: 0.005786  [ 7525/11687]\n",
      "loss: 0.002177  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082317 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.005055  [   25/11687]\n",
      "loss: 0.003081  [ 2525/11687]\n",
      "loss: 0.086720  [ 5025/11687]\n",
      "loss: 0.003486  [ 7525/11687]\n",
      "loss: 0.021903  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.080723 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.002392  [   25/11687]\n",
      "loss: 0.000811  [ 2525/11687]\n",
      "loss: 0.000859  [ 5025/11687]\n",
      "loss: 0.004152  [ 7525/11687]\n",
      "loss: 0.030187  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.076678 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.032616  [   25/11687]\n",
      "loss: 0.001709  [ 2525/11687]\n",
      "loss: 0.003043  [ 5025/11687]\n",
      "loss: 0.040083  [ 7525/11687]\n",
      "loss: 0.048658  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.081984 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.066821  [   25/11687]\n",
      "loss: 0.021528  [ 2525/11687]\n",
      "loss: 0.061451  [ 5025/11687]\n",
      "loss: 0.022453  [ 7525/11687]\n",
      "loss: 0.000524  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.087871 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001562  [   25/11687]\n",
      "loss: 0.066551  [ 2525/11687]\n",
      "loss: 0.026248  [ 5025/11687]\n",
      "loss: 0.000932  [ 7525/11687]\n",
      "loss: 0.010652  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.092046 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.008507  [   25/11687]\n",
      "loss: 0.000336  [ 2525/11687]\n",
      "loss: 0.020321  [ 5025/11687]\n",
      "loss: 0.003941  [ 7525/11687]\n",
      "loss: 0.000422  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.084792 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000508  [   25/11687]\n",
      "loss: 0.002268  [ 2525/11687]\n",
      "loss: 0.001614  [ 5025/11687]\n",
      "loss: 0.002598  [ 7525/11687]\n",
      "loss: 0.024503  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.076029 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.003822  [   25/11687]\n",
      "loss: 0.000470  [ 2525/11687]\n",
      "loss: 0.006309  [ 5025/11687]\n",
      "loss: 0.000237  [ 7525/11687]\n",
      "loss: 0.001999  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.080221 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.006171  [   25/11687]\n",
      "loss: 0.009592  [ 2525/11687]\n",
      "loss: 0.000515  [ 5025/11687]\n",
      "loss: 0.002192  [ 7525/11687]\n",
      "loss: 0.000484  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.083152 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.008898  [   25/11687]\n",
      "loss: 0.013845  [ 2525/11687]\n",
      "loss: 0.009252  [ 5025/11687]\n",
      "loss: 0.055187  [ 7525/11687]\n",
      "loss: 0.000892  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.090665 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.006559  [   25/11687]\n",
      "loss: 0.000644  [ 2525/11687]\n",
      "loss: 0.010837  [ 5025/11687]\n",
      "loss: 0.001499  [ 7525/11687]\n",
      "loss: 0.002268  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.080003 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.003654  [   25/11687]\n",
      "loss: 0.002163  [ 2525/11687]\n",
      "loss: 0.001058  [ 5025/11687]\n",
      "loss: 0.002370  [ 7525/11687]\n",
      "loss: 0.004323  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.076901 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.003509  [   25/11687]\n",
      "loss: 0.008713  [ 2525/11687]\n",
      "loss: 0.006193  [ 5025/11687]\n",
      "loss: 0.007657  [ 7525/11687]\n",
      "loss: 0.003520  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.082252 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.001040  [   25/11687]\n",
      "loss: 0.004557  [ 2525/11687]\n",
      "loss: 0.002808  [ 5025/11687]\n",
      "loss: 0.000486  [ 7525/11687]\n",
      "loss: 0.003458  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.093196 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.000042  [   25/11687]\n",
      "loss: 0.000411  [ 2525/11687]\n",
      "loss: 0.012533  [ 5025/11687]\n",
      "loss: 0.030182  [ 7525/11687]\n",
      "loss: 0.003822  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.099265 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.010603  [   25/11687]\n",
      "loss: 0.002199  [ 2525/11687]\n",
      "loss: 0.000403  [ 5025/11687]\n",
      "loss: 0.000714  [ 7525/11687]\n",
      "loss: 0.002090  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.102227 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.000768  [   25/11687]\n",
      "loss: 0.000193  [ 2525/11687]\n",
      "loss: 0.007916  [ 5025/11687]\n",
      "loss: 0.000919  [ 7525/11687]\n",
      "loss: 0.001405  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.098879 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.001580  [   25/11687]\n",
      "loss: 0.010789  [ 2525/11687]\n",
      "loss: 0.004310  [ 5025/11687]\n",
      "loss: 0.003056  [ 7525/11687]\n",
      "loss: 0.005224  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.084621 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.009934  [   25/11687]\n",
      "loss: 0.000308  [ 2525/11687]\n",
      "loss: 0.005255  [ 5025/11687]\n",
      "loss: 0.002582  [ 7525/11687]\n",
      "loss: 0.000746  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.097232 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.013975  [   25/11687]\n",
      "loss: 0.000133  [ 2525/11687]\n",
      "loss: 0.036830  [ 5025/11687]\n",
      "loss: 0.000646  [ 7525/11687]\n",
      "loss: 0.000325  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.098867 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.002761  [   25/11687]\n",
      "loss: 0.006299  [ 2525/11687]\n",
      "loss: 0.061301  [ 5025/11687]\n",
      "loss: 0.000969  [ 7525/11687]\n",
      "loss: 0.000244  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.093996 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.077725  [   25/11687]\n",
      "loss: 0.005158  [ 2525/11687]\n",
      "loss: 0.001647  [ 5025/11687]\n",
      "loss: 0.000139  [ 7525/11687]\n",
      "loss: 0.002182  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.091752 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.001669  [   25/11687]\n",
      "loss: 0.009526  [ 2525/11687]\n",
      "loss: 0.001369  [ 5025/11687]\n",
      "loss: 0.107773  [ 7525/11687]\n",
      "loss: 0.001363  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.098414 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.014101  [   25/11687]\n",
      "loss: 0.001643  [ 2525/11687]\n",
      "loss: 0.006748  [ 5025/11687]\n",
      "loss: 0.000351  [ 7525/11687]\n",
      "loss: 0.000137  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.144220 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.014696  [   25/11687]\n",
      "loss: 0.002050  [ 2525/11687]\n",
      "loss: 0.001936  [ 5025/11687]\n",
      "loss: 0.024031  [ 7525/11687]\n",
      "loss: 0.000163  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.091758 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.000097  [   25/11687]\n",
      "loss: 0.002022  [ 2525/11687]\n",
      "loss: 0.001209  [ 5025/11687]\n",
      "loss: 0.000021  [ 7525/11687]\n",
      "loss: 0.001235  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.102008 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.000077  [   25/11687]\n",
      "loss: 0.000136  [ 2525/11687]\n",
      "loss: 0.036265  [ 5025/11687]\n",
      "loss: 0.000606  [ 7525/11687]\n",
      "loss: 0.000724  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.114262 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000521  [   25/11687]\n",
      "loss: 0.000590  [ 2525/11687]\n",
      "loss: 0.000268  [ 5025/11687]\n",
      "loss: 0.000766  [ 7525/11687]\n",
      "loss: 0.004104  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.102424 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.000155  [   25/11687]\n",
      "loss: 0.000246  [ 2525/11687]\n",
      "loss: 0.001801  [ 5025/11687]\n",
      "loss: 0.003028  [ 7525/11687]\n",
      "loss: 0.005168  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.103345 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000321  [   25/11687]\n",
      "loss: 0.000342  [ 2525/11687]\n",
      "loss: 0.000297  [ 5025/11687]\n",
      "loss: 0.009103  [ 7525/11687]\n",
      "loss: 0.002111  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.096985 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.000041  [   25/11687]\n",
      "loss: 0.003385  [ 2525/11687]\n",
      "loss: 0.001927  [ 5025/11687]\n",
      "loss: 0.000554  [ 7525/11687]\n",
      "loss: 0.000279  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.099144 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.013599  [   25/11687]\n",
      "loss: 0.000068  [ 2525/11687]\n",
      "loss: 0.012494  [ 5025/11687]\n",
      "loss: 0.001097  [ 7525/11687]\n",
      "loss: 0.000120  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.109496 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000102  [   25/11687]\n",
      "loss: 0.001519  [ 2525/11687]\n",
      "loss: 0.000266  [ 5025/11687]\n",
      "loss: 0.000439  [ 7525/11687]\n",
      "loss: 0.000014  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.097457 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000061  [   25/11687]\n",
      "loss: 0.001318  [ 2525/11687]\n",
      "loss: 0.001037  [ 5025/11687]\n",
      "loss: 0.004858  [ 7525/11687]\n",
      "loss: 0.000188  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.101488 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000187  [   25/11687]\n",
      "loss: 0.000030  [ 2525/11687]\n",
      "loss: 0.005973  [ 5025/11687]\n",
      "loss: 0.000017  [ 7525/11687]\n",
      "loss: 0.000109  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.110941 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.007318  [   25/11687]\n",
      "loss: 0.001047  [ 2525/11687]\n",
      "loss: 0.003748  [ 5025/11687]\n",
      "loss: 0.015284  [ 7525/11687]\n",
      "loss: 0.000442  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.108495 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000023  [   25/11687]\n",
      "loss: 0.001209  [ 2525/11687]\n",
      "loss: 0.000927  [ 5025/11687]\n",
      "loss: 0.001542  [ 7525/11687]\n",
      "loss: 0.000388  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.096410 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.000473  [   25/11687]\n",
      "loss: 0.002661  [ 2525/11687]\n",
      "loss: 0.000299  [ 5025/11687]\n",
      "loss: 0.001460  [ 7525/11687]\n",
      "loss: 0.051573  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.130731 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000556  [   25/11687]\n",
      "loss: 0.000020  [ 2525/11687]\n",
      "loss: 0.000038  [ 5025/11687]\n",
      "loss: 0.000114  [ 7525/11687]\n",
      "loss: 0.002090  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.116860 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.006765  [   25/11687]\n",
      "loss: 0.000442  [ 2525/11687]\n",
      "loss: 0.000101  [ 5025/11687]\n",
      "loss: 0.000872  [ 7525/11687]\n",
      "loss: 0.000061  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.115960 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.081628  [   25/11687]\n",
      "loss: 0.002076  [ 2525/11687]\n",
      "loss: 0.000060  [ 5025/11687]\n",
      "loss: 0.005298  [ 7525/11687]\n",
      "loss: 0.000165  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.111257 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000183  [   25/11687]\n",
      "loss: 0.000846  [ 2525/11687]\n",
      "loss: 0.000168  [ 5025/11687]\n",
      "loss: 0.001894  [ 7525/11687]\n",
      "loss: 0.009083  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.102823 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000129  [   25/11687]\n",
      "loss: 0.000064  [ 2525/11687]\n",
      "loss: 0.000187  [ 5025/11687]\n",
      "loss: 0.010627  [ 7525/11687]\n",
      "loss: 0.000051  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.108618 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000153  [   25/11687]\n",
      "loss: 0.000293  [ 2525/11687]\n",
      "loss: 0.000494  [ 5025/11687]\n",
      "loss: 0.009394  [ 7525/11687]\n",
      "loss: 0.001055  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.118823 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.004436  [   25/11687]\n",
      "loss: 0.003368  [ 2525/11687]\n",
      "loss: 0.000343  [ 5025/11687]\n",
      "loss: 0.000032  [ 7525/11687]\n",
      "loss: 0.002194  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.111155 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000360  [   25/11687]\n",
      "loss: 0.000093  [ 2525/11687]\n",
      "loss: 0.000378  [ 5025/11687]\n",
      "loss: 0.000326  [ 7525/11687]\n",
      "loss: 0.000016  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.118617 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000018  [   25/11687]\n",
      "loss: 0.000032  [ 2525/11687]\n",
      "loss: 0.001370  [ 5025/11687]\n",
      "loss: 0.001991  [ 7525/11687]\n",
      "loss: 0.000062  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.110801 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000020  [   25/11687]\n",
      "loss: 0.000325  [ 2525/11687]\n",
      "loss: 0.000410  [ 5025/11687]\n",
      "loss: 0.001643  [ 7525/11687]\n",
      "loss: 0.000626  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.113793 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.009052  [   25/11687]\n",
      "loss: 0.006989  [ 2525/11687]\n",
      "loss: 0.005950  [ 5025/11687]\n",
      "loss: 0.000374  [ 7525/11687]\n",
      "loss: 0.000354  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.112996 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000300  [   25/11687]\n",
      "loss: 0.071726  [ 2525/11687]\n",
      "loss: 0.000014  [ 5025/11687]\n",
      "loss: 0.001405  [ 7525/11687]\n",
      "loss: 0.002659  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.110642 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000076  [   25/11687]\n",
      "loss: 0.000114  [ 2525/11687]\n",
      "loss: 0.000057  [ 5025/11687]\n",
      "loss: 0.000902  [ 7525/11687]\n",
      "loss: 0.000257  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.110414 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000015  [   25/11687]\n",
      "loss: 0.000109  [ 2525/11687]\n",
      "loss: 0.000129  [ 5025/11687]\n",
      "loss: 0.000038  [ 7525/11687]\n",
      "loss: 0.000038  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.100777 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.000405  [   25/11687]\n",
      "loss: 0.000017  [ 2525/11687]\n",
      "loss: 0.000103  [ 5025/11687]\n",
      "loss: 0.000171  [ 7525/11687]\n",
      "loss: 0.000027  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.128515 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.049420  [   25/11687]\n",
      "loss: 0.000015  [ 2525/11687]\n",
      "loss: 0.000113  [ 5025/11687]\n",
      "loss: 0.000109  [ 7525/11687]\n",
      "loss: 0.000009  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.118581 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000256  [   25/11687]\n",
      "loss: 0.003690  [ 2525/11687]\n",
      "loss: 0.000008  [ 5025/11687]\n",
      "loss: 0.000164  [ 7525/11687]\n",
      "loss: 0.000082  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.105201 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000002  [   25/11687]\n",
      "loss: 0.000100  [ 2525/11687]\n",
      "loss: 0.000002  [ 5025/11687]\n",
      "loss: 0.001860  [ 7525/11687]\n",
      "loss: 0.001302  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.116331 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000269  [   25/11687]\n",
      "loss: 0.002189  [ 2525/11687]\n",
      "loss: 0.000059  [ 5025/11687]\n",
      "loss: 0.000008  [ 7525/11687]\n",
      "loss: 0.003329  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.118848 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.000047  [   25/11687]\n",
      "loss: 0.000318  [ 2525/11687]\n",
      "loss: 0.000043  [ 5025/11687]\n",
      "loss: 0.000474  [ 7525/11687]\n",
      "loss: 0.000150  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.105797 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.000372  [   25/11687]\n",
      "loss: 0.000249  [ 2525/11687]\n",
      "loss: 0.000029  [ 5025/11687]\n",
      "loss: 0.001689  [ 7525/11687]\n",
      "loss: 0.000075  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.114547 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000018  [   25/11687]\n",
      "loss: 0.000001  [ 2525/11687]\n",
      "loss: 0.000006  [ 5025/11687]\n",
      "loss: 0.000006  [ 7525/11687]\n",
      "loss: 0.000139  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.125203 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000023  [   25/11687]\n",
      "loss: 0.000193  [ 2525/11687]\n",
      "loss: 0.000102  [ 5025/11687]\n",
      "loss: 0.001263  [ 7525/11687]\n",
      "loss: 0.000062  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.133621 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.007587  [   25/11687]\n",
      "loss: 0.000018  [ 2525/11687]\n",
      "loss: 0.001471  [ 5025/11687]\n",
      "loss: 0.000372  [ 7525/11687]\n",
      "loss: 0.000020  [10025/11687]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.134662 \n",
      "\n",
      "Training and Validation Done!\n"
     ]
    }
   ],
   "source": [
    "trainLoss = []\n",
    "testLoss = []\n",
    "valLoss = []\n",
    "acc = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, pymodel1, loss_fn, optimizer1, trainLoss)\n",
    "    validate(pymodel1, val_dataloader, loss_fn, valLoss, acc)\n",
    "\n",
    "print(\"Training and Validation Done!\")\n",
    "\n",
    "# After training, you can use the test_loop function to evaluate on a separate test set.\n",
    "#test_loop(test_dataloader, pymodel1, loss_fn, testLoss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            all_predictions.extend(pred.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1439    1    0    6]\n",
      " [   4   59    1    1]\n",
      " [  16    4  744    0]\n",
      " [  21    0    1 1043]]\n",
      "\n",
      "Precision:\n",
      "[0.9722973  0.921875   0.99731903 0.99333333]\n",
      "\n",
      "Recall:\n",
      "[0.99515906 0.90769231 0.97382199 0.97934272]\n",
      "\n",
      "F1 Score:\n",
      "[0.98359535 0.91472868 0.98543046 0.98628842]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming num_classes is the number of classes in your problem (4 in this case)\n",
    "num_classes = 4\n",
    "\n",
    "def calculate_multiclass_metrics(predictions, labels, num_classes):\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(labels, predictions, labels=range(num_classes))\n",
    "\n",
    "    # Calculate precision, recall, and F1 score for each class\n",
    "    precision = precision_score(labels, predictions, average=None, labels=range(num_classes))\n",
    "    recall = recall_score(labels, predictions, average=None, labels=range(num_classes))\n",
    "    f1 = f1_score(labels, predictions, average=None, labels=range(num_classes))\n",
    "\n",
    "    return conf_matrix, precision, recall, f1\n",
    "\n",
    "\n",
    "###This is used to test predictions from the dataset that is SIMILAR to the training data\n",
    "###\n",
    "###\n",
    "# Use the test_loop function to get predictions on the test set\n",
    "test_predictions, test_labels = evaluate_predictions(pymodel1, test_dataloader)\n",
    "\n",
    "# Calculate multiclass metrics\n",
    "conf_matrix, precision, recall, f1 = calculate_multiclass_metrics(test_predictions, test_labels, num_classes)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nPrecision:\")\n",
    "print(precision)\n",
    "print(\"\\nRecall:\")\n",
    "print(recall)\n",
    "print(\"\\nF1 Score:\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_image\\\\spag.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predicted_class_name, input_image\n\u001b[0;32m     31\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_image\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mspag.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m predicted_label, image_input \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpymodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe predicted label for the image is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36mpredict_single_image\u001b[1;34m(model, image_path, class_labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_single_image\u001b[39m(model, image_path, class_labels):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Load and preprocess the image\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      8\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mResize(image_size),\n\u001b[0;32m      9\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mCenterCrop(image_size),\n\u001b[0;32m     10\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     11\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m     12\u001b[0m     ])\n\u001b[0;32m     14\u001b[0m     input_image \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_image\\\\spag.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_single_image(model, image_path, class_labels):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    input_image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Set the model to evaluation mode and make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_image = input_image.to(device)\n",
    "        output = model(input_image)\n",
    "\n",
    "    # Interpret the model output\n",
    "    predicted_index = output.argmax(1).item()\n",
    "    predicted_class_name = class_mapping[predicted_index]\n",
    "    \n",
    "\n",
    "\n",
    "    return predicted_class_name, input_image\n",
    "\n",
    "\n",
    "image_path = \"test_image\\\\spag.jpg\"\n",
    "predicted_label, image_input = predict_single_image(pymodel1, image_path, class_mapping)\n",
    "print(f\"The predicted label for the image is: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'CNNModelV0_3.pth'\n",
    "torch.save(pymodel1.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Convert model to a .onnx file so that I can convert it to something i can use\n",
    "torch.onnx.export(pymodel1, image_input, 'CNN_Model.onnx', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pymodel1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobile_optimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_for_mobile\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpymodel1\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      5\u001b[0m example \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m227\u001b[39m, \u001b[38;5;241m227\u001b[39m)\n\u001b[0;32m      6\u001b[0m traced_script_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mtrace(pymodel1, example)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pymodel1' is not defined"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "pymodel1.eval()\n",
    "example = torch.rand(1, 3, 227, 227)\n",
    "traced_script_module = torch.jit.trace(pymodel1, example)\n",
    "optimized_traced_model = optimize_for_mobile(traced_script_module)\n",
    "optimized_traced_model._save_for_lite_interpreter(\"app/src/main/assets/model.ptl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
